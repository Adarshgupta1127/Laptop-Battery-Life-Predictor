{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This script creates a complete starter project folder with code files for the\n",
        "# \"Laptop Battery Life Predictor\" end-to-end ML project.\n",
        "#\n",
        "# You'll get:\n",
        "# - data logger (collector.py)\n",
        "# - shared sensor utilities (sensors.py)\n",
        "# - model training & evaluation (train.py, evaluate.py)\n",
        "# - live prediction CLI (predict_now.py)\n",
        "# - optional Streamlit app (app.py)\n",
        "# - a quick simulator to generate synthetic data for testing (simulate_data.py)\n",
        "# - requirements.txt and a README.md\n",
        "# - A zipped archive you can download\n",
        "#\n",
        "# After this cell runs, you'll see a download link at the end.\n",
        "\n",
        "import os, json, textwrap, zipfile, pathlib\n",
        "\n",
        "root = \"/mnt/data/battery_ml\"\n",
        "os.makedirs(root, exist_ok=True)\n",
        "os.makedirs(f\"{root}/data\", exist_ok=True)\n",
        "os.makedirs(f\"{root}/models\", exist_ok=True)\n",
        "os.makedirs(f\"{root}/reports\", exist_ok=True)\n",
        "\n",
        "# sensors.py: shared functions for sampling system metrics (psutil), brightness, and feature list\n",
        "sensors_py = r'''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Shared utilities to read system sensors and build a feature row.\n",
        "\"\"\"\n",
        "import time\n",
        "import psutil\n",
        "from typing import Optional, Dict, Any, Tuple\n",
        "try:\n",
        "    import screen_brightness_control as sbc  # optional; supports Windows/Linux\n",
        "except Exception:  # pragma: no cover\n",
        "    sbc = None\n",
        "\n",
        "\n",
        "def _get_brightness() -> Optional[float]:\n",
        "    \"\"\"Return screen brightness in [0, 100] if available, else None.\"\"\"\n",
        "    try:\n",
        "        if sbc:\n",
        "            val = sbc.get_brightness()\n",
        "            # sbc.get_brightness() may return list of displays on some systems\n",
        "            if isinstance(val, list):\n",
        "                if len(val) == 0:\n",
        "                    return None\n",
        "                return float(sum(val) / len(val))\n",
        "            return float(val)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "\n",
        "def _get_active_apps_count(threshold_cpu: float = 0.5, threshold_mem_mb: float = 100.0) -> int:\n",
        "    \"\"\"\n",
        "    Approximate \"apps open\" by counting processes owned by the current user that are\n",
        "    either using noticeable CPU or memory. This is cross-platform and avoids GUI APIs.\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    for proc in psutil.process_iter(['cpu_percent', 'memory_info', 'username']):\n",
        "        try:\n",
        "            cpu = proc.info.get('cpu_percent', 0.0) or 0.0\n",
        "            mem = proc.info.get('memory_info').rss / (1024 * 1024) if proc.info.get('memory_info') else 0.0\n",
        "            if cpu >= threshold_cpu or mem >= threshold_mem_mb:\n",
        "                count += 1\n",
        "        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
        "            continue\n",
        "    return int(count)\n",
        "\n",
        "\n",
        "FEATURE_COLUMNS = [\n",
        "    'battery_percent',\n",
        "    'cpu_percent',\n",
        "    'cpu_freq_mhz',\n",
        "    'ram_percent',\n",
        "    'disk_read_kb_s',\n",
        "    'disk_write_kb_s',\n",
        "    'net_sent_kb_s',\n",
        "    'net_recv_kb_s',\n",
        "    'brightness',\n",
        "    'screen_on',\n",
        "    'active_apps_count'\n",
        "]\n",
        "\n",
        "\n",
        "def sample_features(prev_state: Optional[Dict[str, Any]] = None, cpu_interval: float = 1.0\n",
        "                   ) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Collect a single row of features and Target (if available) from the current system.\n",
        "    Returns (row_dict, new_prev_state). The row includes 'hours_left' target when known.\n",
        "    \"\"\"\n",
        "    now = time.time()\n",
        "\n",
        "    # Battery\n",
        "    battery = None\n",
        "    try:\n",
        "        battery = psutil.sensors_battery()\n",
        "    except Exception:\n",
        "        battery = None\n",
        "\n",
        "    plugged = getattr(battery, \"power_plugged\", None) if battery else None\n",
        "    percent = getattr(battery, \"percent\", None) if battery else None\n",
        "    secsleft = getattr(battery, \"secsleft\", None) if battery else None\n",
        "\n",
        "    # CPU / RAM\n",
        "    cpu_percent = psutil.cpu_percent(interval=cpu_interval)\n",
        "    try:\n",
        "        cpu_freq = psutil.cpu_freq()\n",
        "        cpu_freq_mhz = float(cpu_freq.current) if cpu_freq else None\n",
        "    except Exception:\n",
        "        cpu_freq_mhz = None\n",
        "    ram_percent = float(psutil.virtual_memory().percent)\n",
        "\n",
        "    # IO & Network (rates per second since prev_state)\n",
        "    disk = psutil.disk_io_counters()\n",
        "    net = psutil.net_io_counters()\n",
        "    disk_read_kb_s = disk_write_kb_s = net_sent_kb_s = net_recv_kb_s = None\n",
        "    if prev_state is not None:\n",
        "        dt = max(1e-9, now - prev_state['t'])\n",
        "        disk_read_kb_s  = max(0.0, (disk.read_bytes  - prev_state['disk_read_bytes'])  / 1024.0 / dt)\n",
        "        disk_write_kb_s = max(0.0, (disk.write_bytes - prev_state['disk_write_bytes']) / 1024.0 / dt)\n",
        "        net_sent_kb_s   = max(0.0, (net.bytes_sent   - prev_state['net_bytes_sent'])   / 1024.0 / dt)\n",
        "        net_recv_kb_s   = max(0.0, (net.bytes_recv   - prev_state['net_bytes_recv'])   / 1024.0 / dt)\n",
        "\n",
        "    # Brightness & apps\n",
        "    brightness = _get_brightness()\n",
        "    screen_on = (brightness is not None) and (float(brightness) > 0.0)\n",
        "    active_apps_count = _get_active_apps_count()\n",
        "\n",
        "    # Target\n",
        "    hours_left = None\n",
        "    try:\n",
        "        if battery and not plugged and secsleft not in (psutil.POWER_TIME_UNKNOWN, psutil.POWER_TIME_UNLIMITED):\n",
        "            hours_left = float(secsleft) / 3600.0\n",
        "    except Exception:\n",
        "        hours_left = None\n",
        "\n",
        "    row = {\n",
        "        'battery_percent': percent,\n",
        "        'cpu_percent': cpu_percent,\n",
        "        'cpu_freq_mhz': cpu_freq_mhz,\n",
        "        'ram_percent': ram_percent,\n",
        "        'disk_read_kb_s': disk_read_kb_s,\n",
        "        'disk_write_kb_s': disk_write_kb_s,\n",
        "        'net_sent_kb_s': net_sent_kb_s,\n",
        "        'net_recv_kb_s': net_recv_kb_s,\n",
        "        'brightness': brightness,\n",
        "        'screen_on': float(screen_on) if screen_on is not None else None,\n",
        "        'active_apps_count': active_apps_count,\n",
        "        'on_ac_power': plugged,\n",
        "        'secsleft_raw': secsleft,\n",
        "        'hours_left': hours_left,\n",
        "    }\n",
        "\n",
        "    new_prev = {\n",
        "        't': now,\n",
        "        'disk_read_bytes': disk.read_bytes,\n",
        "        'disk_write_bytes': disk.write_bytes,\n",
        "        'net_bytes_sent': net.bytes_sent,\n",
        "        'net_bytes_recv': net.bytes_recv,\n",
        "    }\n",
        "    return row, new_prev\n",
        "'''\n",
        "with open(f\"{root}/sensors.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(sensors_py)\n",
        "\n",
        "# collector.py: continuous logger\n",
        "collector_py = r'''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Collects laptop telemetry every N seconds and appends to data/battery_log.csv\n",
        "Stop with Ctrl+C. You can set env vars:\n",
        "  BATTERY_LOG_PATH (default: data/battery_log.csv)\n",
        "  BATTERY_LOG_INTERVAL (seconds, default: 60)\n",
        "\"\"\"\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from sensors import sample_features\n",
        "\n",
        "LOG_PATH = os.environ.get(\"BATTERY_LOG_PATH\", \"data/battery_log.csv\")\n",
        "INTERVAL = float(os.environ.get(\"BATTERY_LOG_INTERVAL\", \"60\"))\n",
        "\n",
        "def ensure_parent(path: str):\n",
        "    parent = os.path.dirname(path)\n",
        "    if parent and not os.path.exists(parent):\n",
        "        os.makedirs(parent, exist_ok=True)\n",
        "\n",
        "def main():\n",
        "    ensure_parent(LOG_PATH)\n",
        "    prev = None\n",
        "    print(f\"[collector] Logging to {LOG_PATH} every {INTERVAL:.0f}s. Press Ctrl+C to stop.\")\n",
        "    try:\n",
        "        while True:\n",
        "            row, prev = sample_features(prev)\n",
        "            row['timestamp'] = pd.Timestamp.now().isoformat()\n",
        "            df = pd.DataFrame([row])\n",
        "            header = not os.path.exists(LOG_PATH) or os.path.getsize(LOG_PATH) == 0\n",
        "            df.to_csv(LOG_PATH, mode='a', index=False, header=header)\n",
        "            print(f\"[collector] wrote row @ {row['timestamp']} | target hours_left={row['hours_left']}\")\n",
        "            # sleep remaining interval (we already blocked ~1s inside sample_features for cpu_percent)\n",
        "            time.sleep(max(0.0, INTERVAL - 1.0))\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n[collector] Stopped. Goodbye!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "with open(f\"{root}/collector.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(collector_py)\n",
        "\n",
        "# train.py: trains models and saves the best pipeline\n",
        "train_py = r'''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Train a regression model to predict remaining battery hours.\n",
        "Usage:\n",
        "  python train.py --csv data/battery_log.csv --out models/best_model.joblib\n",
        "If you have no real data yet, first run simulate_data.py to generate data.\n",
        "\"\"\"\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "from sensors import FEATURE_COLUMNS\n",
        "\n",
        "def load_and_clean(csv_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    # ensure timestamp is datetime if present\n",
        "    if 'timestamp' in df.columns:\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
        "\n",
        "    # Filter to rows with target present and meaningful\n",
        "    df = df[df['hours_left'].notna()]\n",
        "    # Use only when on battery (not plugged in)\n",
        "    if 'on_ac_power' in df.columns:\n",
        "        df = df[df['on_ac_power'] == False]  # noqa: E712\n",
        "\n",
        "    # Some OSes sometimes report crazy secsleft; clamp target to a sensible range (0 - 15 hours)\n",
        "    df = df[(df['hours_left'] > 0) & (df['hours_left'] <= 15)]\n",
        "    df = df.drop_duplicates().reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "def build_pipelines(numeric_features: List[str]):\n",
        "    pre = ColumnTransformer([\n",
        "        (\"num\", Pipeline([\n",
        "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"scaler\", StandardScaler())\n",
        "        ]), numeric_features),\n",
        "    ])\n",
        "\n",
        "    models = {\n",
        "        \"LinearRegression\": LinearRegression(),\n",
        "        \"RandomForest\": RandomForestRegressor(\n",
        "            n_estimators=300, max_depth=None, min_samples_leaf=2, n_jobs=-1, random_state=42\n",
        "        ),\n",
        "        \"GradientBoosting\": GradientBoostingRegressor(random_state=42)\n",
        "    }\n",
        "\n",
        "    pipelines = {name: Pipeline([(\"pre\", pre), (\"model\", model)]) for name, model in models.items()}\n",
        "    return pipelines\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--csv\", default=\"data/battery_log.csv\")\n",
        "    ap.add_argument(\"--out\", default=\"models/best_model.joblib\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    if not os.path.exists(args.csv):\n",
        "        raise SystemExit(f\"Data file not found: {args.csv}. Run collector.py or simulate_data.py first.\")\n",
        "\n",
        "    df = load_and_clean(args.csv)\n",
        "\n",
        "    if len(df) < 80:\n",
        "        print(f\"[train] WARNING: only {len(df)} usable rows. More data will improve accuracy.\")\n",
        "\n",
        "    X = df[FEATURE_COLUMNS]\n",
        "    y = df['hours_left']\n",
        "\n",
        "    # time-aware split if timestamp exists; else random split\n",
        "    if 'timestamp' in df.columns and df['timestamp'].notna().any():\n",
        "        df_sorted = df.sort_values('timestamp')\n",
        "        X = df_sorted[FEATURE_COLUMNS]\n",
        "        y = df_sorted['hours_left']\n",
        "        # use last 20% as test\n",
        "        split_idx = int(0.8 * len(df_sorted))\n",
        "        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
        "        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
        "    else:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    pipelines = build_pipelines(FEATURE_COLUMNS)\n",
        "    results = []\n",
        "\n",
        "    for name, pipe in pipelines.items():\n",
        "        pipe.fit(X_train, y_train)\n",
        "        preds = pipe.predict(X_test)\n",
        "        mae = mean_absolute_error(y_test, preds)\n",
        "        rmse = mean_squared_error(y_test, preds, squared=False)\n",
        "        r2 = r2_score(y_test, preds)\n",
        "        results.append({\"name\": name, \"mae\": mae, \"rmse\": rmse, \"r2\": r2})\n",
        "        print(f\"[train] {name:16s} | MAE={mae:.3f} | RMSE={rmse:.3f} | R2={r2:.3f}\")\n",
        "\n",
        "    # pick best by MAE\n",
        "    results_sorted = sorted(results, key=lambda d: d[\"mae\"])\n",
        "    best_name = results_sorted[0][\"name\"]\n",
        "    best_pipe = pipelines[best_name]\n",
        "    os.makedirs(os.path.dirname(args.out), exist_ok=True)\n",
        "    joblib.dump(best_pipe, args.out)\n",
        "\n",
        "    # Save metrics\n",
        "    metrics_path = os.path.join(os.path.dirname(args.out), \"metrics.json\")\n",
        "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"results\": results_sorted, \"n_train\": len(X_train), \"n_test\": len(X_test)}, f, indent=2)\n",
        "\n",
        "    print(f\"[train] Saved best model: {args.out} ({best_name})\")\n",
        "    print(f\"[train] Metrics saved to: {metrics_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "with open(f\"{root}/train.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(train_py)\n",
        "\n",
        "# evaluate.py: deeper evaluation + permutation importance plot\n",
        "evaluate_py = r'''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Evaluate a saved model and produce a feature importance plot via permutation importance.\n",
        "Usage:\n",
        "  python evaluate.py --csv data/battery_log.csv --model models/best_model.joblib --out reports/feature_importance.png\n",
        "\"\"\"\n",
        "import argparse\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sensors import FEATURE_COLUMNS\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_data(csv_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    if 'timestamp' in df.columns:\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
        "        df = df.sort_values('timestamp')\n",
        "    df = df[df['hours_left'].notna()]\n",
        "    if 'on_ac_power' in df.columns:\n",
        "        df = df[df['on_ac_power'] == False]  # noqa: E712\n",
        "    df = df[(df['hours_left'] > 0) & (df['hours_left'] <= 15)]\n",
        "    return df.reset_index(drop=True)\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--csv\", default=\"data/battery_log.csv\")\n",
        "    ap.add_argument(\"--model\", default=\"models/best_model.joblib\")\n",
        "    ap.add_argument(\"--out\", default=\"reports/feature_importance.png\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    model = joblib.load(args.model)\n",
        "    df = load_data(args.csv)\n",
        "    if len(df) < 30:\n",
        "        print(\"[evaluate] WARNING: dataset is quite small; importance may be noisy.\")\n",
        "\n",
        "    # Use last 20% as test\n",
        "    split_idx = int(0.8 * len(df))\n",
        "    X_test = df[FEATURE_COLUMNS].iloc[split_idx:]\n",
        "    y_test = df['hours_left'].iloc[split_idx:]\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    print(f\"[evaluate] Test MAE={mae:.3f} | RMSE={rmse:.3f} | R2={r2:.3f}\")\n",
        "\n",
        "    # Permutation importance on test set\n",
        "    result = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=42, n_jobs=-1)\n",
        "    importances = result.importances_mean\n",
        "    stds = result.importances_std\n",
        "\n",
        "    order = np.argsort(importances)[::-1]\n",
        "    names = np.array(FEATURE_COLUMNS)[order]\n",
        "    imps = importances[order]\n",
        "    errs = stds[order]\n",
        "\n",
        "    # Plot (no custom colors per instructions)\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.title(\"Permutation Feature Importance\")\n",
        "    plt.bar(range(len(names)), imps, yerr=errs)\n",
        "    plt.xticks(range(len(names)), names, rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    os.makedirs(os.path.dirname(args.out), exist_ok=True)\n",
        "    plt.savefig(args.out, dpi=160)\n",
        "    print(f\"[evaluate] Saved feature importance plot to {args.out}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "with open(f\"{root}/evaluate.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(evaluate_py)\n",
        "\n",
        "# predict_now.py: live prediction using current sensors\n",
        "predict_now_py = r'''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Loads the trained model and predicts remaining hours for your current system state.\n",
        "Usage:\n",
        "  python predict_now.py --model models/best_model.joblib\n",
        "\"\"\"\n",
        "import argparse\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from sensors import sample_features, FEATURE_COLUMNS\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--model\", default=\"models/best_model.joblib\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    model = joblib.load(args.model)\n",
        "\n",
        "    row, prev = sample_features(prev_state=None)  # initial row has rate features = None\n",
        "    # Take a second sample to compute IO/network rates\n",
        "    row, prev = sample_features(prev_state=prev)\n",
        "\n",
        "    X = pd.DataFrame([{k: row.get(k) for k in FEATURE_COLUMNS}])\n",
        "    pred_hours = float(model.predict(X)[0])\n",
        "    pred_mins = int(pred_hours * 60)\n",
        "    print(f\"[predict_now] Predicted remaining time: {pred_hours:.2f} hours (~{pred_mins} minutes)\")\n",
        "    print(\"[predict_now] Features used:\")\n",
        "    print(X.to_string(index=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "with open(f\"{root}/predict_now.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(predict_now_py)\n",
        "\n",
        "# app.py: simple Streamlit app\n",
        "app_py = r'''#!/usr/bin/env python3\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import joblib\n",
        "from sensors import sample_features, FEATURE_COLUMNS\n",
        "\n",
        "MODEL_PATH = os.environ.get(\"MODEL_PATH\", \"models/best_model.joblib\")\n",
        "LOG_PATH = os.environ.get(\"BATTERY_LOG_PATH\", \"data/battery_log.csv\")\n",
        "\n",
        "st.set_page_config(page_title=\"Laptop Battery Life Predictor\", layout=\"centered\")\n",
        "\n",
        "st.title(\"ðŸ”‹ Laptop Battery Life Predictor\")\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    st.warning(\"Model not found. Train it first with `python train.py`.\")\n",
        "    st.stop()\n",
        "\n",
        "model = joblib.load(MODEL_PATH)\n",
        "\n",
        "# Live prediction block\n",
        "st.subheader(\"Live Prediction\")\n",
        "with st.spinner(\"Sampling system metrics...\"):\n",
        "    row, prev = sample_features(None)\n",
        "    time.sleep(1.0)  # ensure rates have time to change\n",
        "    row, _ = sample_features(prev)\n",
        "\n",
        "import pandas as pd\n",
        "X = pd.DataFrame([{k: row.get(k) for k in FEATURE_COLUMNS}])\n",
        "pred_hours = float(model.predict(X)[0])\n",
        "st.metric(\"Predicted Remaining Time\", f\"{pred_hours:.2f} hours\", help=\"Based on current CPU, RAM, brightness, I/O and network activity\")\n",
        "\n",
        "st.write(\"Current features:\")\n",
        "st.dataframe(X)\n",
        "\n",
        "# Historical log viewer\n",
        "st.subheader(\"Recent Log (if available)\")\n",
        "if os.path.exists(LOG_PATH):\n",
        "    df = pd.read_csv(LOG_PATH)\n",
        "    if 'timestamp' in df.columns:\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
        "        df = df.sort_values('timestamp').tail(240)  # last ~4 hours if 1 min interval\n",
        "    st.dataframe(df.tail(50))\n",
        "else:\n",
        "    st.info(\"No log file found yet. Start the collector with `python collector.py`.\")\n",
        "'''\n",
        "with open(f\"{root}/app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(app_py)\n",
        "\n",
        "# simulate_data.py: bootstrap synthetic dataset for demo/training\n",
        "simulate_py = r'''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Generate a synthetic battery log to let you train/evaluate the pipeline\n",
        "before you have real data. Writes to data/simulated_battery_log.csv\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "N = 1200  # ~20 hours of minute-level data\n",
        "timestamps = pd.date_range(\"2025-01-01\", periods=N, freq=\"1min\")\n",
        "\n",
        "battery_percent = np.clip(100 - np.linspace(0, 60, N) + rng.normal(0, 1.8, N), 5, 100)\n",
        "cpu_percent = np.clip(rng.normal(22, 12, N) + 10*np.sin(np.linspace(0, 12, N)), 1, 98)\n",
        "cpu_freq_mhz = np.clip(1200 + 800*(cpu_percent/100) + rng.normal(0, 80, N), 800, 4000)\n",
        "ram_percent = np.clip(rng.normal(55, 10, N) + 0.2*cpu_percent, 10, 98)\n",
        "disk_read_kb_s  = np.clip(np.abs(rng.normal(50, 80, N)), 0, 5000)\n",
        "disk_write_kb_s = np.clip(np.abs(rng.normal(40, 60, N)), 0, 5000)\n",
        "net_sent_kb_s   = np.clip(np.abs(rng.normal(20, 40, N)), 0, 4000)\n",
        "net_recv_kb_s   = np.clip(np.abs(rng.normal(30, 60, N)), 0, 4000)\n",
        "brightness = np.clip(rng.normal(60, 25, N), 0, 100)\n",
        "screen_on = (brightness > 0).astype(float)\n",
        "active_apps_count = np.clip((cpu_percent/15 + rng.normal(3, 2, N)).round().astype(int), 1, 50)\n",
        "\n",
        "# A simple \"physics-inspired\" target: higher cpu/brightness/apps/io drain faster -> fewer hours left\n",
        "drain_factor = (\n",
        "    0.012*cpu_percent +\n",
        "    0.010*ram_percent +\n",
        "    0.006*brightness +\n",
        "    0.002*active_apps_count +\n",
        "    0.00015*(disk_read_kb_s + disk_write_kb_s) +\n",
        "    0.00012*(net_sent_kb_s + net_recv_kb_s)\n",
        ")\n",
        "# Convert drain factor to remaining hours: smaller drain -> longer hours (bounded 0-12)\n",
        "hours_left = np.clip(12 - 0.08*drain_factor + rng.normal(0, 0.5, N), 0.2, 12)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'timestamp': timestamps,\n",
        "    'battery_percent': battery_percent,\n",
        "    'cpu_percent': cpu_percent,\n",
        "    'cpu_freq_mhz': cpu_freq_mhz,\n",
        "    'ram_percent': ram_percent,\n",
        "    'disk_read_kb_s': disk_read_kb_s,\n",
        "    'disk_write_kb_s': disk_write_kb_s,\n",
        "    'net_sent_kb_s': net_sent_kb_s,\n",
        "    'net_recv_kb_s': net_recv_kb_s,\n",
        "    'brightness': brightness,\n",
        "    'screen_on': screen_on,\n",
        "    'active_apps_count': active_apps_count,\n",
        "    'on_ac_power': False,\n",
        "    'secsleft_raw': (hours_left * 3600).round(),\n",
        "    'hours_left': hours_left\n",
        "})\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "out = \"data/simulated_battery_log.csv\"\n",
        "df.to_csv(out, index=False)\n",
        "print(f\"[simulate_data] Wrote {len(df)} rows to {out}\")\n",
        "'''\n",
        "with open(f\"{root}/simulate_data.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(simulate_py)\n",
        "\n",
        "# requirements.txt\n",
        "requirements = \"\"\"\\\n",
        "pandas\n",
        "numpy\n",
        "psutil\n",
        "scikit-learn\n",
        "joblib\n",
        "matplotlib\n",
        "screen_brightness_control\n",
        "streamlit\n",
        "\"\"\"\n",
        "with open(f\"{root}/requirements.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(requirements)\n",
        "\n",
        "# README.md\n",
        "readme = r'''# ðŸ”‹ Laptop Battery Life Predictor (End-to-End ML Project)\n",
        "\n",
        "**Goal:** Predict remaining battery time (hours) using real-time laptop telemetry: CPU load, RAM, I/O, network, screen brightness, and active app count.\n",
        "\n",
        "This project is designed to be:\n",
        "- **Beginner-friendly:** minimal tools, simple Python scripts.\n",
        "- **End-to-end:** data collection â†’ modeling â†’ evaluation â†’ live prediction / app.\n",
        "- **Recruiter-friendly:** real hardware + ML + small app.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“¦ Project Structure\n",
        "\n"
      ],
      "metadata": {
        "id": "AKITuu7PGCrf",
        "outputId": "bd348be4-57bc-4f34-f2ac-95e5ba53bb43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-994384677.py, line 577)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-994384677.py\"\u001b[0;36m, line \u001b[0;32m577\u001b[0m\n\u001b[0;31m    readme = r'''# ðŸ”‹ Laptop Battery Life Predictor (End-to-End ML Project)\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZhIEjhopGDkr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}